{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b92150c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "# Data processing and manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "from typing import Iterable, Any, Tuple, Dict\n",
    "\n",
    "\n",
    "# Machine learning models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, log_loss, average_precision_score, balanced_accuracy_score, accuracy_score\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Custom models\n",
    "import importlib\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '../src')))\n",
    "\n",
    "import preprocess_data as ppd\n",
    "import GAMinferenceModels_V2 as gam_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419277e9",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "566d129f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data_file = \"../Data/hourly/hourly_weather_by_state.csv\"\n",
    "power_load_file = \"../Data/hourly/hourly_load_by_state.csv\"\n",
    "failure_data_file = \"../Data/hourly/hourly_failure_dataset_compressed.csv\"\n",
    "\n",
    "all_data_df, _, feature_names, target_columns, integer_encoding = ppd.preprocess_data(failure_data_path=failure_data_file,\n",
    "                                                                                        weather_data_path=weather_data_file,\n",
    "                                                                                        power_load_data_path=power_load_file,\n",
    "                                                                                        feature_names=['Temperature', 'Relative_humidity', 'Load', 'State'],\n",
    "                                                                                        cyclic_features=[\"Season\", \"Month\", \"DayOfWeek\", \"DayOfYear\"],\n",
    "                                                                                        state_one_hot=False,\n",
    "                                                                                        initial_MC_state_filter='all',\n",
    "                                                                                        technology_filter=['Gas Turbine/Jet Engine (Simple Cycle Operation)'],\n",
    "                                                                                        test_periods=None\n",
    "                                                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0c6c800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporal features for regional classifiers\n",
    "all_data_df['month_sin'] = np.sin(2*np.pi*all_data_df['Datetime_UTC'].dt.month/12)\n",
    "all_data_df['month_cos'] = np.cos(2*np.pi*all_data_df['Datetime_UTC'].dt.month/12)\n",
    "\n",
    "# Get list of states from one-hot encoded columns\n",
    "idx2state = {v: k for k, v in integer_encoding['States'].items()}\n",
    "all_data_df['State'] = all_data_df['State'].apply(lambda x: idx2state[x])\n",
    "states_list = all_data_df['State'].unique().tolist()\n",
    "states_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c89a084c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States considered: ['ALABAMA', 'ARIZONA', 'ARKANSAS', 'CALIFORNIA', 'COLORADO', 'CONNECTICUT', 'DELAWARE', 'FLORIDA', 'GEORGIA', 'IDAHO', 'ILLINOIS', 'INDIANA', 'IOWA', 'KANSAS', 'KENTUCKY', 'LOUISIANA', 'MAINE', 'MARYLAND', 'MASSACHUSETTS', 'MICHIGAN', 'MINNESOTA', 'MISSISSIPPI', 'MISSOURI', 'MONTANA', 'NEBRASKA', 'NEVADA', 'NEW HAMPSHIRE', 'NEW JERSEY', 'NEW MEXICO', 'NEW YORK', 'NORTH CAROLINA', 'NORTH DAKOTA', 'OHIO', 'OKLAHOMA', 'OREGON', 'PENNSYLVANIA', 'SOUTH CAROLINA', 'SOUTH DAKOTA', 'TENNESSEE', 'TEXAS', 'UTAH', 'VERMONT', 'VIRGINIA', 'WASHINGTON', 'WEST VIRGINIA', 'WISCONSIN', 'WYOMING']\n"
     ]
    }
   ],
   "source": [
    "print(\"States considered:\", states_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95657138",
   "metadata": {},
   "source": [
    "### 2022-2023 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dda1f274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general_test_period = [(pd.Timestamp('2022-01-01 00:00:00'), pd.Timestamp('2023-12-31 23:00:00'))]\n",
    "general_test_period = [(pd.Timestamp('2022-01-01 00:00:00', tz='UTC'), pd.Timestamp('2023-12-31 23:00:00', tz='UTC'))]\n",
    "\n",
    "specific_test_periods_per_state = {state: general_test_period for state in states_list}\n",
    "\n",
    "folder_name = \"2022_2023_test_periods\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac61716d",
   "metadata": {},
   "source": [
    "### Test on extreme event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da741362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_extreme_temperature_events(\n",
    "    all_data_df: pd.DataFrame,\n",
    "    states_list,\n",
    "    *,\n",
    "    temp_col=\"Temperature\",\n",
    "    datetime_col=\"Datetime_UTC\",\n",
    "    state_col=\"State\",\n",
    "    cold_percentile=5,\n",
    "    hot_percentile=85,\n",
    "    min_duration=2,\n",
    "):\n",
    "    \"\"\"\n",
    "    Detect extreme cold and hot events per state.\n",
    "\n",
    "    Definitions\n",
    "    -----------\n",
    "    - Daily mean temperature computed from hourly data\n",
    "    - Extreme cold: daily mean <= cold_percentile\n",
    "    - Extreme hot : daily mean >= hot_percentile\n",
    "    - Event = at least `min_duration` consecutive days\n",
    "    - Events returned as (start_day, end_day), inclusive\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    extreme_cold_events_dt : dict[state -> list[(start_day, end_day)]]\n",
    "    extreme_hot_events_dt  : dict[state -> list[(start_day, end_day)]]\n",
    "    \"\"\"\n",
    "\n",
    "    extreme_cold_events_dt = defaultdict(list)\n",
    "    extreme_hot_events_dt  = defaultdict(list)\n",
    "\n",
    "    for state in states_list:\n",
    "        # --- isolate state data ---\n",
    "        state_data = (\n",
    "            all_data_df.loc[all_data_df[state_col] == state, [datetime_col, temp_col]]\n",
    "            .drop_duplicates(subset=[datetime_col])\n",
    "            .sort_values(datetime_col)\n",
    "            .copy()\n",
    "        )\n",
    "\n",
    "        if state_data.empty:\n",
    "            continue\n",
    "\n",
    "        # --- compute daily mean temperature ---\n",
    "        state_data[\"Day\"] = state_data[datetime_col].dt.floor(\"D\")\n",
    "        daily = (\n",
    "            state_data\n",
    "            .groupby(\"Day\", as_index=False)[temp_col]\n",
    "            .mean()\n",
    "            .rename(columns={temp_col: \"Daily_mean_Temperature\"})\n",
    "            .sort_values(\"Day\")\n",
    "        )\n",
    "\n",
    "        temps = daily[\"Daily_mean_Temperature\"].to_numpy()\n",
    "\n",
    "        # --- thresholds ---\n",
    "        cold_thr = np.percentile(temps, cold_percentile)\n",
    "        hot_thr  = np.percentile(temps, hot_percentile)\n",
    "\n",
    "        is_cold = temps <= cold_thr\n",
    "        is_hot  = temps >= hot_thr\n",
    "\n",
    "        # --- helper to extract runs ---\n",
    "        def extract_runs(mask, days, min_len):\n",
    "            \"\"\"\n",
    "            mask : boolean array\n",
    "            days : array of day timestamps\n",
    "            \"\"\"\n",
    "            runs = []\n",
    "            d = np.diff(np.r_[0, mask.astype(int), 0])\n",
    "            starts = np.where(d == 1)[0]\n",
    "            ends   = np.where(d == -1)[0]  # exclusive\n",
    "\n",
    "            for s, e in zip(starts, ends):\n",
    "                if (e - s) >= min_len:\n",
    "                    runs.append((days[s], days[e - 1]))  # inclusive end\n",
    "            return runs\n",
    "\n",
    "        days = daily[\"Day\"].to_numpy()\n",
    "\n",
    "        # --- extract events ---\n",
    "        extreme_cold_events_dt[state] = extract_runs(\n",
    "            is_cold, days, min_duration\n",
    "        )\n",
    "        extreme_hot_events_dt[state] = extract_runs(\n",
    "            is_hot, days, min_duration\n",
    "        )\n",
    "\n",
    "    return extreme_cold_events_dt, extreme_hot_events_dt\n",
    "\n",
    "def select_extreme_events(\n",
    "        all_extreme_events: list[Tuple[pd.Timestamp, pd.Timestamp]],\n",
    "        method: str = 'longest',\n",
    "        n: int = 2\n",
    "    ) -> list[Tuple[pd.Timestamp, pd.Timestamp]]:\n",
    "    if method == 'longest':\n",
    "        # Select the n longest events\n",
    "        selected_events = sorted(all_extreme_events, key=lambda x: x[1] - x[0], reverse=True)[:n]\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid method {method}. Choose 'longest'.\")\n",
    "    return selected_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7e11e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_cold = 1\n",
    "# n_hot = 1\n",
    "\n",
    "# extreme_cold_events, extreme_hot_events = detect_extreme_temperature_events(\n",
    "#     all_data_df,\n",
    "#     states_list,\n",
    "#     temp_col=\"Temperature\",\n",
    "#     datetime_col=\"Datetime_UTC\",\n",
    "#     state_col=\"State\",\n",
    "#     cold_percentile=5,\n",
    "#     hot_percentile=95,\n",
    "#     min_duration=2,\n",
    "# )\n",
    "\n",
    "# selected_cold_events = {\n",
    "#     state: select_extreme_events(events, method='longest', n=n_cold)\n",
    "#     for state, events in extreme_cold_events.items()}\n",
    "# selected_hot_events = {\n",
    "#     state: select_extreme_events(events, method='longest', n=n_hot)\n",
    "#     for state, events in extreme_hot_events.items()}\n",
    "\n",
    "# round_of_cold_events = {i: {state: [events[i]] for state, events in selected_cold_events.items() if events} for i in range(n_cold)}\n",
    "# round_of_hot_events = {i: {state: [events[i]] for state, events in selected_hot_events.items() if events} for i in range(n_hot)}\n",
    "\n",
    "# folder_name_cold = \"Extreme_cold_events\"\n",
    "# folder_name_hot = \"Extreme_hot_events\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b5393a",
   "metadata": {},
   "source": [
    "# Naive model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f84f80",
   "metadata": {},
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec147d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sets = {}\n",
    "test_sets = {}\n",
    "\n",
    "for state in states_list:\n",
    "    test_start, test_end = specific_test_periods_per_state[state][0][0], specific_test_periods_per_state[state][0][1]\n",
    "    train_df = all_data_df.loc[\n",
    "        (all_data_df['State'] == state) &\n",
    "        (~all_data_df['Datetime_UTC'].between(test_start, test_end)),\n",
    "    ].copy()\n",
    "\n",
    "    test_df = all_data_df.loc[\n",
    "        (all_data_df['State'] == state) &\n",
    "        (all_data_df['Datetime_UTC'].between(test_start, test_end)),\n",
    "    ].copy()\n",
    "\n",
    "    train_sets[state] = train_df\n",
    "    test_sets[state] = test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c7658c",
   "metadata": {},
   "source": [
    "### Compute empirical transition frequency, and export tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0b6b094",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:12<00:00,  3.88it/s]\n"
     ]
    }
   ],
   "source": [
    "for state in tqdm(states_list):\n",
    "    train_df = train_sets[state]\n",
    "    test_df = test_sets[state].copy()\n",
    "\n",
    "    probs_naive = {}\n",
    "    for initial_state in [0,1,2]:\n",
    "        df_init = train_df.loc[train_df['Initial_gen_state'] == initial_state]\n",
    "        for final_state in [0,1,2]:\n",
    "            y = df_init['Final_gen_state']==final_state\n",
    "            w = df_init['Data_weight'].values\n",
    "            if len(y) == 0:\n",
    "                f = np.nan\n",
    "            else:\n",
    "                f = np.average(y, weights=w)\n",
    "            probs_naive[(initial_state, final_state)] = f\n",
    "\n",
    "\n",
    "    test_df['pAA'] = probs_naive[(0,0)]\n",
    "    test_df['pAD'] = probs_naive[(0,1)]\n",
    "    test_df['pAO'] = probs_naive[(0,2)]\n",
    "    test_df['pDA'] = probs_naive[(1,0)]\n",
    "    test_df['pDD'] = probs_naive[(1,1)]\n",
    "    test_df['pOA'] = probs_naive[(2,0)]\n",
    "    test_df['pOO'] = probs_naive[(2,2)]\n",
    "\n",
    "\n",
    "    output_folder = Path(f\"../Results/GAM/{folder_name}/Naive_model/\")\n",
    "    output_folder.mkdir(parents=True, exist_ok=True)\n",
    "    output_file = output_folder / f\"naive_failure_probabilities_{state}.csv\"\n",
    "    test_df.to_csv(output_file, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574b866c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ScenarioGeneration",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
