{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c884896d",
   "metadata": {},
   "source": [
    "# Create the failure dataset at hourly resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db40ff38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '../src')))\n",
    "import data_processing as dp\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60e08e3",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44c4e319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Events : 2013\n",
      "Loading Events : 2014\n",
      "Loading Events : 2015\n",
      "Loading Events : 2016\n",
      "Loading Events : 2017\n",
      "Loading Events : 2018\n",
      "Loading Events : 2019\n",
      "Loading Events : 2020\n",
      "Loading Events : 2021\n",
      "Loading Events : 2022\n",
      "Loading Events : 2023\n",
      "Loading Events : 2024\n",
      "Warning: Ignoring columns ['RegionCode'] in GADS_Events_2024_20250505.xlsx\n",
      "Loaded 6005103 events\n"
     ]
    }
   ],
   "source": [
    "events_df = dp.load_events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bec82ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering events by cause codes...\n",
      "Kept 839971 events out of 6005103 (13.99%) after filtering by cause codes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Merging duplicated events: 100%|██████████| 839971/839971 [00:11<00:00, 73682.18it/s] \n",
      "Adding state and region: 100%|██████████| 834847/834847 [01:06<00:00, 12510.98it/s]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(dp)\n",
    "\n",
    "filtered_events_df = dp.filter_events(events_df, \n",
    "                                      CauseCodes=['U1', 'U2', 'U3', 'D1', 'D2', 'D3', 'SF'], \n",
    "                                      filter_fuel=False, \n",
    "                                      exclude_states=['Other','Mexico','South America'], \n",
    "                                      include_states=None,\n",
    "                                      add_fuel_failure=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe9deb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Performances : 2013\n",
      "Loading Performances : 2014\n",
      "Loading Performances : 2015\n",
      "Loading Performances : 2016\n",
      "Loading Performances : 2017\n",
      "Loading Performances : 2018\n",
      "Loading Performances : 2019\n",
      "Loading Performances : 2020\n",
      "Loading Performances : 2021\n",
      "Loading Performances : 2022\n",
      "Warning: Ignoring columns ['PumpingHours'] in GADS_Performance_2022_20230605.xlsx\n",
      "Loading Performances : 2023\n",
      "Warning: Ignoring columns ['PumpingHours'] in GADS_Performance_2023_20240422.xlsx\n",
      "Loading Performances : 2024\n",
      "Warning: Ignoring columns ['RegionCode', 'PumpingHours'] in GADS_Performance_2024_20250505.xlsx\n",
      "Loaded 1035652 events\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9305/9305 [00:07<00:00, 1179.03it/s]\n"
     ]
    }
   ],
   "source": [
    "units_start_end = dp.get_units_start_end()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2741e1f9",
   "metadata": {},
   "source": [
    "## Format transition data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0023169d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping from U.S. state / Canadian province abbreviations to representative IANA time zones\n",
    "STATE_TIMEZONE = {\n",
    "    # --- U.S. ---\n",
    "    \"AL\": \"America/Chicago\", \"AK\": \"America/Anchorage\", \"AZ\": \"America/Phoenix\",\n",
    "    \"AR\": \"America/Chicago\", \"CA\": \"America/Los_Angeles\", \"CO\": \"America/Denver\",\n",
    "    \"CT\": \"America/New_York\", \"DE\": \"America/New_York\", \"DC\": \"America/New_York\",\n",
    "    \"FL\": \"America/New_York\", \"GA\": \"America/New_York\", \"HI\": \"Pacific/Honolulu\",\n",
    "    \"ID\": \"America/Boise\", \"IL\": \"America/Chicago\", \"IN\": \"America/Indiana/Indianapolis\",\n",
    "    \"IA\": \"America/Chicago\", \"KS\": \"America/Chicago\", \"KY\": \"America/New_York\",\n",
    "    \"LA\": \"America/Chicago\", \"ME\": \"America/New_York\", \"MD\": \"America/New_York\",\n",
    "    \"MA\": \"America/New_York\", \"MI\": \"America/Detroit\", \"MN\": \"America/Chicago\",\n",
    "    \"MS\": \"America/Chicago\", \"MO\": \"America/Chicago\", \"MT\": \"America/Denver\",\n",
    "    \"NE\": \"America/Chicago\", \"NV\": \"America/Los_Angeles\", \"NH\": \"America/New_York\",\n",
    "    \"NJ\": \"America/New_York\", \"NM\": \"America/Denver\", \"NY\": \"America/New_York\",\n",
    "    \"NC\": \"America/New_York\", \"ND\": \"America/Chicago\", \"OH\": \"America/New_York\",\n",
    "    \"OK\": \"America/Chicago\", \"OR\": \"America/Los_Angeles\", \"PA\": \"America/New_York\",\n",
    "    \"RI\": \"America/New_York\", \"SC\": \"America/New_York\", \"SD\": \"America/Chicago\",\n",
    "    \"TN\": \"America/Chicago\", \"TX\": \"America/Chicago\", \"UT\": \"America/Denver\",\n",
    "    \"VT\": \"America/New_York\", \"VA\": \"America/New_York\", \"WA\": \"America/Los_Angeles\",\n",
    "    \"WV\": \"America/New_York\", \"WI\": \"America/Chicago\", \"WY\": \"America/Denver\",\n",
    "\n",
    "    # --- Canada ---\n",
    "    \"AB\": \"America/Edmonton\", \"BC\": \"America/Vancouver\", \"MB\": \"America/Winnipeg\",\n",
    "    \"NB\": \"America/Moncton\", \"NL\": \"America/St_Johns\", \"NS\": \"America/Halifax\",\n",
    "    \"NT\": \"America/Yellowknife\", \"NU\": \"America/Iqaluit\", \"ON\": \"America/Toronto\",\n",
    "    \"PE\": \"America/Halifax\", \"QC\": \"America/Montreal\", \"SK\": \"America/Regina\",\n",
    "    \"YT\": \"America/Whitehorse\",\n",
    "}\n",
    "\n",
    "# Load state abbreviations\n",
    "state_files = \"../data/ghcn-states.txt\"\n",
    "state2abv = {}\n",
    "with open(state_files, \"r\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip().split()\n",
    "        state2abv[' '.join(line[1:])] = line[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be30003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7166/7166 [30:02<00:00,  3.98it/s]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "transition_data_compressed = defaultdict(pd.DataFrame)\n",
    "\n",
    "for unit_id, events_unit in tqdm(filtered_events_df.groupby('UnitID')):\n",
    "    # Store the transitions for this unit\n",
    "    unit_transitions_data = {\"Datetime_local\":[], # at the start of each hour\n",
    "                            \"Initial_gen_state\":[],\n",
    "                            \"Final_gen_state\":[]\n",
    "                            }\n",
    "\n",
    "    # Unit metadata\n",
    "    unit_geo_state = events_unit[\"State\"].iloc[0]\n",
    "    unit_technology = events_unit[\"UnitTypeCodeName\"].iloc[0]\n",
    "    state_abv = state2abv.get(unit_geo_state.upper(), None)\n",
    "    tz_name = STATE_TIMEZONE.get(state_abv)\n",
    "\n",
    "    if tz_name is None:\n",
    "        print(f\"⚠️ Unknown timezone for {unit_geo_state}, skipping unit {unit_id}\")\n",
    "        continue\n",
    "\n",
    "    tz = ZoneInfo(tz_name)\n",
    "\n",
    "    # Get start and end time for this unit\n",
    "    start_time_unit_local = pd.Timestamp(units_start_end.loc[\n",
    "                                                        units_start_end['UnitID'] == unit_id, 'First_Operation_Date'\n",
    "                                                      ].values[0])\n",
    "    end_time_unit_local = pd.Timestamp(units_start_end.loc[\n",
    "                                                        units_start_end['UnitID'] == unit_id, 'Last_Operation_Date'\n",
    "                                                    ].values[0])\n",
    "\n",
    "    current_time_local = start_time_unit_local\n",
    "    events_unit = events_unit.sort_values('EventStartDT')\n",
    "    last_state = 'A'\n",
    "    \n",
    "    for _, event in events_unit.iterrows():\n",
    "        event_start_local = event['EventStartDT'].replace(minute=0, second=0, microsecond=0)\n",
    "        event_end_local = event['EventEndDT'].replace(minute=0, second=0, microsecond=0) + pd.Timedelta(hours=1)\n",
    "        state_during_event = event[\"EventTypeCode\"]\n",
    "\n",
    "        # Simplify event type\n",
    "        if state_during_event.startswith('D'):\n",
    "            state_during_event = 'D'\n",
    "        elif state_during_event.startswith('U'):\n",
    "            state_during_event = 'U'\n",
    "        elif state_during_event == 'SF':\n",
    "            if last_state != 'A':\n",
    "                state_during_event = 'U' # Startup failure treated as outage if the unit was not available before\n",
    "            else:\n",
    "                continue # skip startup failure if the unit was available before\n",
    "\n",
    "\n",
    "        # Record 'A' states until the event starts\n",
    "        while current_time_local < event_start_local:\n",
    "            unit_transitions_data[\"Datetime_local\"].append(current_time_local)\n",
    "            unit_transitions_data[\"Initial_gen_state\"].append(last_state)\n",
    "            unit_transitions_data[\"Final_gen_state\"].append('A')\n",
    "            current_time_local += pd.Timedelta(hours=1)\n",
    "            last_state = 'A'\n",
    "        \n",
    "        # Record states during the event\n",
    "        while current_time_local < event_end_local:\n",
    "            unit_transitions_data[\"Datetime_local\"].append(current_time_local)\n",
    "            unit_transitions_data[\"Initial_gen_state\"].append(last_state)\n",
    "            unit_transitions_data[\"Final_gen_state\"].append(state_during_event)\n",
    "            current_time_local += pd.Timedelta(hours=1)\n",
    "            last_state = state_during_event\n",
    "\n",
    "    # Fill 'A' states until end of operation\n",
    "    while current_time_local <= end_time_unit_local:\n",
    "        unit_transitions_data[\"Datetime_local\"].append(current_time_local)\n",
    "        unit_transitions_data[\"Initial_gen_state\"].append(last_state)\n",
    "        unit_transitions_data[\"Final_gen_state\"].append('A')\n",
    "        current_time_local += pd.Timedelta(hours=1)\n",
    "        last_state = 'A'\n",
    "\n",
    "   # --- Create DataFrame and convert local → UTC ---\n",
    "    unit_transitions_df = pd.DataFrame(unit_transitions_data)\n",
    "\n",
    "    # Localize to state timezone and drop invalid (nonexistent) times during DST jump\n",
    "    unit_transitions_df[\"Datetime_UTC\"] = (\n",
    "    pd.to_datetime(unit_transitions_df[\"Datetime_local\"])\n",
    "    .dt.tz_localize(tz, nonexistent=\"NaT\", ambiguous=\"NaT\")   # use .dt accessor\n",
    "    .dt.tz_convert(\"UTC\")\n",
    "    )\n",
    "    unit_transitions_df = unit_transitions_df.dropna(subset=[\"Datetime_UTC\"])\n",
    "\n",
    "    transition_data_compressed[unit_id] = {\n",
    "        \"metadata\": {\n",
    "            \"UnitID\": unit_id,\n",
    "            \"State\": unit_geo_state,\n",
    "            \"Technology\": unit_technology\n",
    "        },\n",
    "        \"transitions\": unit_transitions_df.reset_index(drop=True)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d87ecb",
   "metadata": {},
   "source": [
    "## Export 1 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c30252",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7166/7166 [00:12<00:00, 569.90it/s] \n"
     ]
    }
   ],
   "source": [
    "compressed = True\n",
    "\n",
    "all_data = []\n",
    "for unit_id, unit_data in tqdm(transition_data_compressed.items()):\n",
    "    unit_transitions_df = unit_data[\"transitions\"]\n",
    "    # Filter for the current year\n",
    "    transitions_df = unit_transitions_df.copy()\n",
    "    unit_geo_state = unit_data[\"metadata\"][\"State\"]\n",
    "    unit_technology = unit_data[\"metadata\"][\"Technology\"]\n",
    "\n",
    "    transitions_df[\"Geographical State\"] = unit_geo_state\n",
    "    transitions_df[\"Technology\"] = unit_technology\n",
    "\n",
    "    all_data.append(transitions_df)\n",
    "\n",
    "data_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "if compressed :\n",
    "    compressed_df = data_df.groupby(['Datetime_UTC', 'Initial_gen_state', 'Final_gen_state', 'Geographical State', 'Technology']).size().reset_index(name='Count')\n",
    "    compressed_df.to_csv(f\"../Data/hourly_failure_dataset_compressed.csv\", index=False)\n",
    "else:\n",
    "    data_df.to_csv(f\"../Data/hourly_failure_dataset.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ScenarioGeneration",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
