{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c884896d",
   "metadata": {},
   "source": [
    "# Create the failure dataset at hourly resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db40ff38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '../src')))\n",
    "import data_processing as dp\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60e08e3",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44c4e319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Events : 2013\n",
      "Loading Events : 2014\n",
      "Loading Events : 2015\n",
      "Loading Events : 2016\n",
      "Loading Events : 2017\n",
      "Loading Events : 2018\n",
      "Loading Events : 2019\n",
      "Loading Events : 2020\n",
      "Loading Events : 2021\n",
      "Loading Events : 2022\n",
      "Loading Events : 2023\n",
      "Loading Events : 2024\n",
      "Warning: Ignoring columns ['RegionCode'] in GADS_Events_2024_20250505.xlsx\n",
      "Loaded 6005103 events\n"
     ]
    }
   ],
   "source": [
    "events_df = dp.load_events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bec82ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering events by cause codes...\n",
      "Kept 839971 events out of 6005103 (13.99%) after filtering by cause codes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Merging duplicated events: 100%|██████████| 839971/839971 [00:11<00:00, 72687.29it/s] \n",
      "Adding state and region: 100%|██████████| 834847/834847 [01:07<00:00, 12421.82it/s]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(dp)\n",
    "\n",
    "filtered_events_df = dp.filter_events(events_df, \n",
    "                                      CauseCodes=['U1', 'U2', 'U3', 'D1', 'D2', 'D3', 'SF'], \n",
    "                                      filter_fuel=False, \n",
    "                                      exclude_states=['Other','Mexico','South America'], \n",
    "                                      include_states=None,\n",
    "                                      add_fuel_failure=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe9deb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Performances : 2013\n",
      "Loading Performances : 2014\n",
      "Loading Performances : 2015\n",
      "Loading Performances : 2016\n",
      "Loading Performances : 2017\n",
      "Loading Performances : 2018\n",
      "Loading Performances : 2019\n",
      "Loading Performances : 2020\n",
      "Loading Performances : 2021\n",
      "Loading Performances : 2022\n",
      "Warning: Ignoring columns ['PumpingHours'] in GADS_Performance_2022_20230605.xlsx\n",
      "Loading Performances : 2023\n",
      "Warning: Ignoring columns ['PumpingHours'] in GADS_Performance_2023_20240422.xlsx\n",
      "Loading Performances : 2024\n",
      "Warning: Ignoring columns ['RegionCode', 'PumpingHours'] in GADS_Performance_2024_20250505.xlsx\n",
      "Loaded 1035652 events\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9305/9305 [00:07<00:00, 1195.07it/s]\n"
     ]
    }
   ],
   "source": [
    "units_start_end = dp.get_units_start_end()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2741e1f9",
   "metadata": {},
   "source": [
    "## Format transition data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0023169d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping from U.S. state / Canadian province abbreviations to representative IANA time zones\n",
    "STATE_TIMEZONE = {\n",
    "    # --- U.S. ---\n",
    "    \"AL\": \"America/Chicago\", \"AK\": \"America/Anchorage\", \"AZ\": \"America/Phoenix\",\n",
    "    \"AR\": \"America/Chicago\", \"CA\": \"America/Los_Angeles\", \"CO\": \"America/Denver\",\n",
    "    \"CT\": \"America/New_York\", \"DE\": \"America/New_York\", \"DC\": \"America/New_York\",\n",
    "    \"FL\": \"America/New_York\", \"GA\": \"America/New_York\", \"HI\": \"Pacific/Honolulu\",\n",
    "    \"ID\": \"America/Boise\", \"IL\": \"America/Chicago\", \"IN\": \"America/Indiana/Indianapolis\",\n",
    "    \"IA\": \"America/Chicago\", \"KS\": \"America/Chicago\", \"KY\": \"America/New_York\",\n",
    "    \"LA\": \"America/Chicago\", \"ME\": \"America/New_York\", \"MD\": \"America/New_York\",\n",
    "    \"MA\": \"America/New_York\", \"MI\": \"America/Detroit\", \"MN\": \"America/Chicago\",\n",
    "    \"MS\": \"America/Chicago\", \"MO\": \"America/Chicago\", \"MT\": \"America/Denver\",\n",
    "    \"NE\": \"America/Chicago\", \"NV\": \"America/Los_Angeles\", \"NH\": \"America/New_York\",\n",
    "    \"NJ\": \"America/New_York\", \"NM\": \"America/Denver\", \"NY\": \"America/New_York\",\n",
    "    \"NC\": \"America/New_York\", \"ND\": \"America/Chicago\", \"OH\": \"America/New_York\",\n",
    "    \"OK\": \"America/Chicago\", \"OR\": \"America/Los_Angeles\", \"PA\": \"America/New_York\",\n",
    "    \"RI\": \"America/New_York\", \"SC\": \"America/New_York\", \"SD\": \"America/Chicago\",\n",
    "    \"TN\": \"America/Chicago\", \"TX\": \"America/Chicago\", \"UT\": \"America/Denver\",\n",
    "    \"VT\": \"America/New_York\", \"VA\": \"America/New_York\", \"WA\": \"America/Los_Angeles\",\n",
    "    \"WV\": \"America/New_York\", \"WI\": \"America/Chicago\", \"WY\": \"America/Denver\",\n",
    "\n",
    "    # --- Canada ---\n",
    "    \"AB\": \"America/Edmonton\", \"BC\": \"America/Vancouver\", \"MB\": \"America/Winnipeg\",\n",
    "    \"NB\": \"America/Moncton\", \"NL\": \"America/St_Johns\", \"NS\": \"America/Halifax\",\n",
    "    \"NT\": \"America/Yellowknife\", \"NU\": \"America/Iqaluit\", \"ON\": \"America/Toronto\",\n",
    "    \"PE\": \"America/Halifax\", \"QC\": \"America/Montreal\", \"SK\": \"America/Regina\",\n",
    "    \"YT\": \"America/Whitehorse\",\n",
    "}\n",
    "\n",
    "# Load state abbreviations\n",
    "state_files = \"../data/ghcn-states.txt\"\n",
    "state2abv = {}\n",
    "with open(state_files, \"r\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip().split()\n",
    "        state2abv[' '.join(line[1:])] = line[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3ee86a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7166/7166 [31:36<00:00,  3.78it/s]\n"
     ]
    }
   ],
   "source": [
    "transition_data_compressed = defaultdict(pd.DataFrame)\n",
    "\n",
    "for unit_id, events_unit in tqdm(filtered_events_df.groupby('UnitID')):\n",
    "    # Store the transitions for this unit\n",
    "    unit_transitions_data = {\"Datetime_local\":[], # at the start of each hour\n",
    "                            \"Initial_gen_state\":[],\n",
    "                            \"Final_gen_state\":[],\n",
    "                            \"hours_in_state\": []\n",
    "                            }\n",
    "\n",
    "    # Unit metadata\n",
    "    unit_geo_state = events_unit[\"State\"].iloc[0]\n",
    "    unit_technology = events_unit[\"UnitTypeCodeName\"].iloc[0]\n",
    "    state_abv = state2abv.get(unit_geo_state.upper(), None)\n",
    "    tz_name = STATE_TIMEZONE.get(state_abv)\n",
    "\n",
    "    if tz_name is None:\n",
    "        print(f\"⚠️ Unknown timezone for {unit_geo_state}, skipping unit {unit_id}\")\n",
    "        continue\n",
    "\n",
    "    tz = ZoneInfo(tz_name)\n",
    "\n",
    "    # Get start and end time for this unit\n",
    "    start_time_unit_local = pd.Timestamp(units_start_end.loc[\n",
    "                                                        units_start_end['UnitID'] == unit_id, 'First_Operation_Date'\n",
    "                                                      ].values[0])\n",
    "    end_time_unit_local = pd.Timestamp(units_start_end.loc[\n",
    "                                                        units_start_end['UnitID'] == unit_id, 'Last_Operation_Date'\n",
    "                                                    ].values[0])\n",
    "\n",
    "    current_time_local = start_time_unit_local\n",
    "    events_unit = events_unit.sort_values('EventStartDT')\n",
    "    last_state = 'A'\n",
    "    hours_in_current_state = np.nan\n",
    "    \n",
    "    for _, event in events_unit.iterrows():\n",
    "        if hours_in_current_state > 0:\n",
    "            hours_in_current_state = 1\n",
    "        event_start_local = event['EventStartDT'].replace(minute=0, second=0, microsecond=0)\n",
    "        event_end_local = event['EventEndDT'].replace(minute=0, second=0, microsecond=0) + pd.Timedelta(hours=1)\n",
    "        state_during_event = event[\"EventTypeCode\"]\n",
    "\n",
    "        # Simplify event type\n",
    "        if state_during_event.startswith('D'):\n",
    "            state_during_event = 'D'\n",
    "        elif state_during_event.startswith('U'):\n",
    "            state_during_event = 'U'\n",
    "        elif state_during_event == 'SF':\n",
    "            if last_state != 'A':\n",
    "                state_during_event = 'U' # Startup failure treated as outage if the unit was not available before\n",
    "            else:\n",
    "                continue # skip startup failure if the unit was available before\n",
    "\n",
    "\n",
    "        # Record 'A' states until the event starts\n",
    "        while current_time_local < event_start_local:\n",
    "            unit_transitions_data[\"Datetime_local\"].append(current_time_local)\n",
    "            unit_transitions_data[\"Initial_gen_state\"].append(last_state)\n",
    "            unit_transitions_data[\"Final_gen_state\"].append('A')\n",
    "            unit_transitions_data[\"hours_in_state\"].append(hours_in_current_state)\n",
    "            current_time_local += pd.Timedelta(hours=1)\n",
    "            hours_in_current_state += 1\n",
    "            last_state = 'A'\n",
    "        \n",
    "        # Record states during the event\n",
    "        hours_in_current_state = 1\n",
    "        while current_time_local < event_end_local:\n",
    "            unit_transitions_data[\"Datetime_local\"].append(current_time_local)\n",
    "            unit_transitions_data[\"Initial_gen_state\"].append(last_state)\n",
    "            unit_transitions_data[\"Final_gen_state\"].append(state_during_event)\n",
    "            unit_transitions_data[\"hours_in_state\"].append(hours_in_current_state)\n",
    "            current_time_local += pd.Timedelta(hours=1)\n",
    "            hours_in_current_state += 1\n",
    "            last_state = state_during_event\n",
    "\n",
    "    # Fill 'A' states until end of operation\n",
    "    if hours_in_current_state > 0:\n",
    "        hours_in_current_state = 1\n",
    "    while current_time_local <= end_time_unit_local:\n",
    "        unit_transitions_data[\"Datetime_local\"].append(current_time_local)\n",
    "        unit_transitions_data[\"Initial_gen_state\"].append(last_state)\n",
    "        unit_transitions_data[\"Final_gen_state\"].append('A')\n",
    "        unit_transitions_data[\"hours_in_state\"].append(hours_in_current_state)\n",
    "        current_time_local += pd.Timedelta(hours=1)\n",
    "        hours_in_current_state += 1\n",
    "        last_state = 'A'\n",
    "\n",
    "   # --- Create DataFrame and convert local → UTC ---\n",
    "    unit_transitions_df = pd.DataFrame(unit_transitions_data)\n",
    "\n",
    "    # Localize to state timezone and drop invalid (nonexistent) times during DST jump\n",
    "    unit_transitions_df[\"Datetime_UTC\"] = (\n",
    "    pd.to_datetime(unit_transitions_df[\"Datetime_local\"])\n",
    "    .dt.tz_localize(tz, nonexistent=\"NaT\", ambiguous=\"NaT\")   # use .dt accessor\n",
    "    .dt.tz_convert(\"UTC\")\n",
    "    )\n",
    "    unit_transitions_df = unit_transitions_df.dropna(subset=[\"Datetime_UTC\"])\n",
    "\n",
    "    transition_data_compressed[unit_id] = {\n",
    "        \"metadata\": {\n",
    "            \"UnitID\": unit_id,\n",
    "            \"State\": unit_geo_state,\n",
    "            \"Technology\": unit_technology\n",
    "        },\n",
    "        \"transitions\": unit_transitions_df.reset_index(drop=True)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be30003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7166/7166 [30:28<00:00,  3.92it/s]\n"
     ]
    }
   ],
   "source": [
    "transition_data_compressed = defaultdict(pd.DataFrame)\n",
    "\n",
    "for unit_id, events_unit in tqdm(filtered_events_df.groupby('UnitID')):\n",
    "    # Store the transitions for this unit\n",
    "    unit_transitions_data = {\"Datetime_local\":[], # at the start of each hour\n",
    "                            \"Initial_gen_state\":[],\n",
    "                            \"Final_gen_state\":[],\n",
    "                            }\n",
    "\n",
    "    # Unit metadata\n",
    "    unit_geo_state = events_unit[\"State\"].iloc[0]\n",
    "    unit_technology = events_unit[\"UnitTypeCodeName\"].iloc[0]\n",
    "    state_abv = state2abv.get(unit_geo_state.upper(), None)\n",
    "    tz_name = STATE_TIMEZONE.get(state_abv)\n",
    "\n",
    "    if tz_name is None:\n",
    "        print(f\"⚠️ Unknown timezone for {unit_geo_state}, skipping unit {unit_id}\")\n",
    "        continue\n",
    "\n",
    "    tz = ZoneInfo(tz_name)\n",
    "\n",
    "    # Get start and end time for this unit\n",
    "    start_time_unit_local = pd.Timestamp(units_start_end.loc[\n",
    "                                                        units_start_end['UnitID'] == unit_id, 'First_Operation_Date'\n",
    "                                                      ].values[0])\n",
    "    end_time_unit_local = pd.Timestamp(units_start_end.loc[\n",
    "                                                        units_start_end['UnitID'] == unit_id, 'Last_Operation_Date'\n",
    "                                                    ].values[0])\n",
    "\n",
    "    current_time_local = start_time_unit_local\n",
    "    events_unit = events_unit.sort_values('EventStartDT')\n",
    "    last_state = 'A'\n",
    "    \n",
    "    for _, event in events_unit.iterrows():\n",
    "        event_start_local = event['EventStartDT'].replace(minute=0, second=0, microsecond=0)\n",
    "        event_end_local = event['EventEndDT'].replace(minute=0, second=0, microsecond=0) + pd.Timedelta(hours=1)\n",
    "        state_during_event = event[\"EventTypeCode\"]\n",
    "\n",
    "        # Simplify event type\n",
    "        if state_during_event.startswith('D'):\n",
    "            state_during_event = 'D'\n",
    "        elif state_during_event.startswith('U'):\n",
    "            state_during_event = 'U'\n",
    "        elif state_during_event == 'SF':\n",
    "            if last_state != 'A':\n",
    "                state_during_event = 'U' # Startup failure treated as outage if the unit was not available before\n",
    "            else:\n",
    "                continue # skip startup failure if the unit was available before\n",
    "\n",
    "\n",
    "        # Record 'A' states until the event starts\n",
    "        while current_time_local < event_start_local:\n",
    "            unit_transitions_data[\"Datetime_local\"].append(current_time_local)\n",
    "            unit_transitions_data[\"Initial_gen_state\"].append(last_state)\n",
    "            unit_transitions_data[\"Final_gen_state\"].append('A')\n",
    "            current_time_local += pd.Timedelta(hours=1)\n",
    "            last_state = 'A'\n",
    "        \n",
    "        # Record states during the event\n",
    "        while current_time_local < event_end_local:\n",
    "            unit_transitions_data[\"Datetime_local\"].append(current_time_local)\n",
    "            unit_transitions_data[\"Initial_gen_state\"].append(last_state)\n",
    "            unit_transitions_data[\"Final_gen_state\"].append(state_during_event)\n",
    "            current_time_local += pd.Timedelta(hours=1)\n",
    "            last_state = state_during_event\n",
    "\n",
    "    # Fill 'A' states until end of operation\n",
    "    while current_time_local <= end_time_unit_local:\n",
    "        unit_transitions_data[\"Datetime_local\"].append(current_time_local)\n",
    "        unit_transitions_data[\"Initial_gen_state\"].append(last_state)\n",
    "        unit_transitions_data[\"Final_gen_state\"].append('A')\n",
    "        current_time_local += pd.Timedelta(hours=1)\n",
    "        last_state = 'A'\n",
    "\n",
    "   # --- Create DataFrame and convert local → UTC ---\n",
    "    unit_transitions_df = pd.DataFrame(unit_transitions_data)\n",
    "\n",
    "    # Localize to state timezone and drop invalid (nonexistent) times during DST jump\n",
    "    unit_transitions_df[\"Datetime_UTC\"] = (\n",
    "    pd.to_datetime(unit_transitions_df[\"Datetime_local\"])\n",
    "    .dt.tz_localize(tz, nonexistent=\"NaT\", ambiguous=\"NaT\")   # use .dt accessor\n",
    "    .dt.tz_convert(\"UTC\")\n",
    "    )\n",
    "    unit_transitions_df = unit_transitions_df.dropna(subset=[\"Datetime_UTC\"])\n",
    "\n",
    "    transition_data_compressed[unit_id] = {\n",
    "        \"metadata\": {\n",
    "            \"UnitID\": unit_id,\n",
    "            \"State\": unit_geo_state,\n",
    "            \"Technology\": unit_technology\n",
    "        },\n",
    "        \"transitions\": unit_transitions_df.reset_index(drop=True)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d87ecb",
   "metadata": {},
   "source": [
    "## Export 1 file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3808c896",
   "metadata": {},
   "source": [
    "### Data with $\\Delta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51975e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7166/7166 [00:33<00:00, 212.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Technology: Fossil-Steam, Total Hours: 102802822, D Hours: 13009774, U Hours: 5017043\n",
      "Technology: Combined Cycle Block, Total Hours: 30692826, D Hours: 1249830, U Hours: 780216\n",
      "Technology: Fluidized Bed, Total Hours: 3334733, D Hours: 368548, U Hours: 147542\n",
      "Technology: Gas Turbine/Jet Engine (Simple Cycle Operation), Total Hours: 197294723, D Hours: 5311579, U Hours: 7185922\n",
      "Technology: Nuclear, Total Hours: 10322842, D Hours: 1356159, U Hours: 168664\n",
      "Technology: Pumped Storage/Hydro, Total Hours: 142306412, D Hours: 4519464, U Hours: 5473204\n",
      "Technology: Co-generator Block , Total Hours: 3060246, D Hours: 106008, U Hours: 70627\n",
      "Technology: CC steam units, Total Hours: 29834050, D Hours: 1420680, U Hours: 778298\n",
      "Technology: CC GT units , Total Hours: 61164928, D Hours: 986461, U Hours: 1735637\n",
      "Technology: Miscellaneous, Total Hours: 4022297, D Hours: 355229, U Hours: 167111\n",
      "Technology: Multi-boiler/Multi-turbine, Total Hours: 2023969, D Hours: 291572, U Hours: 73223\n",
      "Technology: CoG steam units , Total Hours: 2849076, D Hours: 90535, U Hours: 159259\n",
      "Technology: CoG GT units, Total Hours: 8862575, D Hours: 82215, U Hours: 406463\n",
      "Technology: Geothermal, Total Hours: 3400142, D Hours: 106784, U Hours: 117274\n",
      "Technology: Internal Combustion/Reciprocating Engines, Total Hours: 1223325, D Hours: 102888, U Hours: 29423\n",
      "Technology: Gas Turbine/Jet Engine with HSRG, Total Hours: 332934, D Hours: 2240, U Hours: 14710\n"
     ]
    }
   ],
   "source": [
    "all_data_by_technology = defaultdict(list)\n",
    "\n",
    "\n",
    "for unit_id, unit_data in tqdm(transition_data_compressed.items()):\n",
    "    unit_transitions_df = unit_data[\"transitions\"]\n",
    "    # Filter for the current year\n",
    "    transitions_df = unit_transitions_df.copy()\n",
    "    unit_geo_state = unit_data[\"metadata\"][\"State\"]\n",
    "    unit_technology = unit_data[\"metadata\"][\"Technology\"]\n",
    "\n",
    "    transitions_df[\"Geographical State\"] = unit_geo_state\n",
    "    transitions_df[\"Technology\"] = unit_technology\n",
    "    all_data_by_technology[unit_technology].append(transitions_df)\n",
    "\n",
    "    # all_data.append(transitions_df)\n",
    "\n",
    "# data_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "for technology, df_list in all_data_by_technology.items():\n",
    "    data_df = pd.concat(df_list, ignore_index=True)\n",
    "    print(f\"Technology: {technology}, Total Hours: {len(data_df)}, D Hours: {(data_df['Final_gen_state'] == 'D').sum()}, U Hours: {(data_df['Final_gen_state'] == 'U').sum()}\")\n",
    "    tech_print = technology.replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "    data_df['Data_weight'] = 1.0\n",
    "    h = data_df[\"hours_in_state\"].values\n",
    "    h = np.floor(np.log10(h)*10)/10\n",
    "    data_df['hours_in_state'] = h\n",
    "    discrete_keys = [\"Datetime_UTC\", \"Geographical State\", \"Initial_gen_state\", \"Final_gen_state\", \"Technology\", \"hours_in_state\"]\n",
    "    agg_dict = {col: \"first\" for col in data_df.columns if col not in [\"Data_weight\"] + discrete_keys}\n",
    "    agg_dict[\"Data_weight\"] = \"sum\"\n",
    "    \n",
    "    data_df = (\n",
    "        data_df.groupby(discrete_keys, as_index=False)\n",
    "        .agg(agg_dict)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    data_df.to_csv(f\"../Data/hourly/by_technology/hourly_failure_deltaTime_dataset_{tech_print}.csv\", index=False)\n",
    "\n",
    "# for technology in data_df[\"Technology\"].unique():\n",
    "#     tech_df = data_df[data_df[\"Technology\"] == technology].copy()\n",
    "#     print(f\"Technology: {technology}, Total Hours: {len(tech_df)}, D Hours: {(tech_df['Final_gen_state'] == 'D').sum()}, U Hours: {(tech_df['Final_gen_state'] == 'U').sum()}\")\n",
    "\n",
    "#     tech_df.to_csv(f\"../Data/hourly/by_technology/hourly_failure_deltaTime_dataset_{technology}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c30252",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7166/7166 [00:12<00:00, 569.90it/s] \n"
     ]
    }
   ],
   "source": [
    "compressed = True\n",
    "\n",
    "all_data = []\n",
    "for unit_id, unit_data in tqdm(transition_data_compressed.items()):\n",
    "    unit_transitions_df = unit_data[\"transitions\"]\n",
    "    # Filter for the current year\n",
    "    transitions_df = unit_transitions_df.copy()\n",
    "    unit_geo_state = unit_data[\"metadata\"][\"State\"]\n",
    "    unit_technology = unit_data[\"metadata\"][\"Technology\"]\n",
    "\n",
    "    transitions_df[\"Geographical State\"] = unit_geo_state\n",
    "    transitions_df[\"Technology\"] = unit_technology\n",
    "\n",
    "    all_data.append(transitions_df)\n",
    "\n",
    "data_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "if compressed :\n",
    "    compressed_df = data_df.groupby(['Datetime_UTC', 'Initial_gen_state', 'Final_gen_state', 'Geographical State', 'Technology']).size().reset_index(name='Count')\n",
    "    compressed_df.to_csv(f\"../Data/hourly_failure_dataset_compressed.csv\", index=False)\n",
    "else:\n",
    "    data_df.to_csv(f\"../Data/hourly_failure_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f936051f",
   "metadata": {},
   "source": [
    "### Export test events not compressed 2022-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02394743",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7166/7166 [00:46<00:00, 153.89it/s]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "test_start = pd.Timestamp('2022-01-01 00:00:00', tz='UTC')\n",
    "test_end = pd.Timestamp('2023-12-31 23:00:00', tz='UTC')\n",
    "\n",
    "test_dataset = []\n",
    "for unit_id, unit_data in tqdm(transition_data_compressed.items()):\n",
    "    unit_transitions_df = unit_data[\"transitions\"]\n",
    "    # Filter for the test period\n",
    "    test_transitions_df = unit_transitions_df.loc[(unit_transitions_df['Datetime_UTC'] >= test_start) & (unit_transitions_df['Datetime_UTC'] <= test_end)].copy()\n",
    "    test_transitions_df = test_transitions_df[['Datetime_UTC', 'Final_gen_state', 'hours_in_state']]\n",
    "    test_transitions_df['Technology'] = unit_data[\"metadata\"][\"Technology\"]\n",
    "    test_transitions_df['State'] = unit_data[\"metadata\"][\"State\"]\n",
    "    test_transitions_df['UnitID'] = unit_id\n",
    "    test_dataset.append(test_transitions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e669e741",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7166/7166 [00:06<00:00, 1133.14it/s]\n"
     ]
    }
   ],
   "source": [
    "test_start = pd.Timestamp('2022-01-01 00:00:00', tz='UTC')\n",
    "test_end = pd.Timestamp('2023-12-31 23:00:00', tz='UTC')\n",
    "\n",
    "test_dataset = []\n",
    "for unit_id, unit_data in tqdm(transition_data_compressed.items()):\n",
    "    unit_transitions_df = unit_data[\"transitions\"]\n",
    "    # Filter for the test period\n",
    "    test_transitions_df = unit_transitions_df.loc[(unit_transitions_df['Datetime_UTC'] >= test_start) & (unit_transitions_df['Datetime_UTC'] <= test_end)].copy()\n",
    "    test_transitions_df = test_transitions_df[['Datetime_UTC', 'Final_gen_state']]\n",
    "    test_transitions_df['Technology'] = unit_data[\"metadata\"][\"Technology\"]\n",
    "    test_transitions_df['State'] = unit_data[\"metadata\"][\"State\"]\n",
    "    test_transitions_df['UnitID'] = unit_id\n",
    "    test_dataset.append(test_transitions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a41d3c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime_UTC</th>\n",
       "      <th>Gen_state</th>\n",
       "      <th>Technology</th>\n",
       "      <th>State</th>\n",
       "      <th>UnitID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01 00:00:00+00:00</td>\n",
       "      <td>A</td>\n",
       "      <td>Combined Cycle Block</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01 01:00:00+00:00</td>\n",
       "      <td>A</td>\n",
       "      <td>Combined Cycle Block</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01 02:00:00+00:00</td>\n",
       "      <td>A</td>\n",
       "      <td>Combined Cycle Block</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01 03:00:00+00:00</td>\n",
       "      <td>A</td>\n",
       "      <td>Combined Cycle Block</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 04:00:00+00:00</td>\n",
       "      <td>A</td>\n",
       "      <td>Combined Cycle Block</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95993802</th>\n",
       "      <td>2023-12-31 19:00:00+00:00</td>\n",
       "      <td>A</td>\n",
       "      <td>Gas Turbine/Jet Engine (Simple Cycle Operation)</td>\n",
       "      <td>Texas</td>\n",
       "      <td>12871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95993803</th>\n",
       "      <td>2023-12-31 20:00:00+00:00</td>\n",
       "      <td>A</td>\n",
       "      <td>Gas Turbine/Jet Engine (Simple Cycle Operation)</td>\n",
       "      <td>Texas</td>\n",
       "      <td>12871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95993804</th>\n",
       "      <td>2023-12-31 21:00:00+00:00</td>\n",
       "      <td>A</td>\n",
       "      <td>Gas Turbine/Jet Engine (Simple Cycle Operation)</td>\n",
       "      <td>Texas</td>\n",
       "      <td>12871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95993805</th>\n",
       "      <td>2023-12-31 22:00:00+00:00</td>\n",
       "      <td>A</td>\n",
       "      <td>Gas Turbine/Jet Engine (Simple Cycle Operation)</td>\n",
       "      <td>Texas</td>\n",
       "      <td>12871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95993806</th>\n",
       "      <td>2023-12-31 23:00:00+00:00</td>\n",
       "      <td>A</td>\n",
       "      <td>Gas Turbine/Jet Engine (Simple Cycle Operation)</td>\n",
       "      <td>Texas</td>\n",
       "      <td>12871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95993807 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Datetime_UTC Gen_state  \\\n",
       "0        2022-01-01 00:00:00+00:00         A   \n",
       "1        2022-01-01 01:00:00+00:00         A   \n",
       "2        2022-01-01 02:00:00+00:00         A   \n",
       "3        2022-01-01 03:00:00+00:00         A   \n",
       "4        2022-01-01 04:00:00+00:00         A   \n",
       "...                            ...       ...   \n",
       "95993802 2023-12-31 19:00:00+00:00         A   \n",
       "95993803 2023-12-31 20:00:00+00:00         A   \n",
       "95993804 2023-12-31 21:00:00+00:00         A   \n",
       "95993805 2023-12-31 22:00:00+00:00         A   \n",
       "95993806 2023-12-31 23:00:00+00:00         A   \n",
       "\n",
       "                                               Technology       State  UnitID  \n",
       "0                                    Combined Cycle Block  New Jersey      30  \n",
       "1                                    Combined Cycle Block  New Jersey      30  \n",
       "2                                    Combined Cycle Block  New Jersey      30  \n",
       "3                                    Combined Cycle Block  New Jersey      30  \n",
       "4                                    Combined Cycle Block  New Jersey      30  \n",
       "...                                                   ...         ...     ...  \n",
       "95993802  Gas Turbine/Jet Engine (Simple Cycle Operation)       Texas   12871  \n",
       "95993803  Gas Turbine/Jet Engine (Simple Cycle Operation)       Texas   12871  \n",
       "95993804  Gas Turbine/Jet Engine (Simple Cycle Operation)       Texas   12871  \n",
       "95993805  Gas Turbine/Jet Engine (Simple Cycle Operation)       Texas   12871  \n",
       "95993806  Gas Turbine/Jet Engine (Simple Cycle Operation)       Texas   12871  \n",
       "\n",
       "[95993807 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset_df = pd.concat(test_dataset, ignore_index=True)\n",
    "test_dataset_df.rename(columns={'Final_gen_state': 'Gen_state'}, inplace=True)\n",
    "test_dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24d62fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_df.to_csv(f\"../Data/hourly_failure_test_dataset_2022_2023.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65461bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ScenarioGeneration",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
